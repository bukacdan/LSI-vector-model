{% extends "base.html" %}
{%  block content %}
<h1 id="lsi-vektorov-model">LSI Vektorový model</h1>
<h2 id="popis-projektu">Popis projektu</h2>
<p>
    Cílem našeho projektu bylo vytvořit webovou aplikaci, která by implementovala LSI vektorový model k vyhledávání nad kolekcí textových dokumentů.
</p>
<p>
    Vstupem do vyhledávacího formuláře je textový dotaz uživatele, podobně jako u klasických webových vyhledávačů, a hodnota přepínače, která určuje, zda bude vyhledáváno v kolekci sekvenčně, nebo optimalizovaně pomocí LSI vektorového modelu.
</p>
<p>
    Výstupem aplikace je seřazený seznam náhledů dokumentů z kolekce, které nejpřesněji odpovídají zadanému dotazu. Daný náhled je možno rozkliknout a přečíst v plném rozsahu.
</p>
<h2 id="zp-sob-e-en-">Způsob řešení</h2>
<h3 id="data">Data</h3>
<p>Za zdroj textových dat jsme si vybrali dataset
<a href="http://qwone.com/~jason/20Newsgroups/">20 newsgroups</a>.
Vstupem z tohoto datasetu je tedy kolekce cca. 20 tisíc textových dokumentů rozdělených téměř rovnoměrně do 20 kategorií. Tento dataset stahujeme přímo pomocí
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html">knihovní funkce</a> 
v scikit-learn.</p>
<h3 id="-i-t-n-dat">Čištění dat</h3>
<p>Textová data mohou obsahovat nežádoucí ruch, proto bylo potřeba je pročistit. S dokumenty postupně provádíme tyto úpravy:</p>
<ol>
<li>všechna písmena převedeme na písmena malá</li>
<li>odstraníme e-mailové adresy</li>
<li>odstraníme non-alfabetické znaky</li>
<li>lematizujeme slova</li>
<li>odstraníme krátká slova</li>
</ol>
<h3 id="vytvo-en-vyhled-vac-ho-modelu">Vytvoření vyhledávacího modelu</h3>
<p>Nejprve si vyrobíme term-by-document matici o rozměrech (<počet dokumentů>, <počet termů>).
Hodnoty v ní převážíme pomocí tf-idf schématu.</p>
<p>Tuto matici dekomponujeme pomocí singular-value-decomposition (SVD) na matice:</p>
<ul>
<li><strong>u</strong><ul>
<li>rozměry: (<počet dokumentů>, <k = počet konceptů>)</li>
<li>concept-by-document matice</li>
</ul>
</li>
<li><strong>s</strong><ul>
<li>rozměry: (<n = počet konceptů>, )</li>
<li>vektor konceptů</li>
</ul>
</li>
<li><strong>vt</strong><ul>
<li>rozměry: (<k = počet konceptů>, <počet termů>)</li>
<li>koncept-by-term matice</li>
</ul>
</li>
</ul>
<h3 id="hled-n-optim-ln-ho-po-tu-koncept-">Hledání optimálního počtu konceptů</h3>
<p>Naším cílem bylo najití optimálního počtu k konceptů tak, aby k bylo co nejnižší (kvůli rychlosti vyhledávání) a zároveň výsledky co nejpřesnější.</p>
<h3 id="zobrazen-dotazu-do-prostoru-koncept-">Zobrazení dotazu do prostoru konceptů</h3>
<p>Dále je zapotřebí zobrazit lematizovaný dotaz uživatele do prostoru konceptů jako vektor, následně změřit kosinovou vzdálenost v tohoto vektoru od ostatních vektorů dokumentů.</p>
<h2 id="implementace">Implementace</h2>
<h3 id="jazyk">Jazyk</h3>
<p>K vývoji jsme použili programovací jazyk <a href="https://www.python.org/">Python</a> 
a mikro webový framework <a href="https://flask.palletsprojects.com/en/1.1.x/">Flask</a>.</p>
<h3 id="knihovny">Knihovny</h3>
<ul>
<li><a href="https://pandas.pydata.org/">Pandas</a> k analýze a zpracování dat</li>
<li><a href="https://numpy.org/">Numpy</a> a <a href="https://www.scipy.org/">Scipy</a> k práci s maticemi</li>
<li><a href="https://www.nltk.org/">NLTK</a> k analýze přirozeného jazyka</li>
<li><a href="https://scikit-learn.org/stable/">scikit-learn</a> k vytváření LSI modelu</li>
<li><a href="https://kneed.readthedocs.io/en/stable/">Kneed</a> k hledání zlomů v křivce optimálního počtu konceptů</li>
</ul>
<p>Při testování našich nápadů jsme využili Jupyter notebook</a>.</p>
<p>Celá aplikace je kontejnerizovaná v <a href="https://www.docker.com/">Dockeru</a>.</p>
<h3 id="stavba-aplikace">Stavba aplikace</h3>
<p>Veškerá logika aplikace se nachází v modulu
lsiModel
respektive ve třídě LSI uvnitř něj. </p>
<p>Důležité třídní metody:</p>
<ul>
<li><p>prepare</p>
<ul>
<li>pokud není lokálně stažen dataset s dokumenty, stáhne je</li>
<li>pročistí dokumenty</li>
<li>vytvoří model pro vyhledávání (ten se vytvoří pouze jednou při inicializaci, poté už zůstává uvnitř třídy)</li>
</ul>
</li>
<li><p>svd_optimal_k</p>
<ul>
<li>nalezne optimální počet konceptů</li>
</ul>
</li>
<li><p>process_query</p>
<ul>
<li>zpracuje dotaz uživatele a promítne jej do prostoru konceptů</li>
<li>změří kosinovou podobnost mezi dotazem a dokumenty</li>
<li>lematizuje dotaz</li>
<li>vrátí list odpovídajících dokumentů k dotazu</li>
</ul>
</li>
<li><p>process_query_seq</p>
<ul>
<li>rozdělí uživatelův dotaz na slova</li>
<li>pro každé slovo sekvenčně prochází term-document matici a vrací dokumenty, ve kterých se slovo nachází</li>
</ul>
</li>
</ul>
<p>Třídu je při prvním spuštění třeba inicializovat. Tato operace může trvat 1-2 minuty. Po celou dobu aplikace do konzole vypisuje, co právě dělá.</p>
<p>Když uživatel potvrdí dotaz ve formuláři na hlavní stránce, je tento dotaz předán LSI třídě. Ta dotaz vyhodnotí a vrátí nazpět list výsledných dokumentů. Ty jsi zobrazeny v seznamu výsledků.</p>
<h2 id="uk-zka-vstupu">Ukázka vstupu</h2>
<div>
    <img {{ url_for('static', filename='./img/user_input.png') }} png" alt="vstup uživatele">
    <p>uživatel zadal vstup &quot;washington&quot; a nevybral možnost vyhledávat sekvenčně</p>
<div>
    <img src={{ url_for('static', filename='./img/search_results.png') }} alt="výsledky vyhledávání">
    <p>Aplikace vrátila 100 výsledků za 0.15s. </p>
<p>Každý výsledek má nad sebou popsaný:</p>
<ul>
<li>původní dotaz</li>
<li>lematizovaný dotaz</li>
<li>úhlovou vzdálenost výslekdu</li>
<li>index dokumentu</li>
<li>kategorii dokumentu</li>
</ul>
<div>
    <img src={{ url_for('static', filename='./img/results_detail.png') }} alt="detail výsledku">
    <p>V horní části obrazovky je původní text (bez našich úprav) v plném rozsahu.</p>
<div>Pod ním jsou vylistované jemu podobné dokumenty.</p>
<h2 id="experiment-ln-sekce">Experimentální sekce</h2>
<p>Nejprve bylo potřeba určit optimální počet K konceptů. Vyzkoušeli jsme pro K hodnoty z intrevalu <1, 200> a pozorovali hodnoty v matici S při singular value decomposition.</p>
<div>
    <img src={{ url_for('static', filename='./img/optimal_components_search.png') }} alt="optimální počet komponent">
    <p><em>Na ose x je vynešen počet konceptů, na ose y hodnoty singular values tedy &quot;důležitost&quot; konceptů. Křivka se lomí v bodě x=15</em></p>
</div>
<p>V dalším experimentu zkoušíme hodnoty pro K z intervalu <1, 50> a inkrementujeme o 2 (pro více hodnot trval výpočet příliš dlouho). Zároveň pro každou hodnotu K zkoušíme dotaz zpracovat s lemmatizací i bez. Výsledky zkoušíme na 4 různých dotazech.</p>
<div>
    <img src={{ url_for('static', filename='./img/experiment.png') }} alt="výsledky hledání pro různé K">
    <p>V grafech je vidět, že pro nižší hodnoty K je kosinová vzdálenost menší, nicméně při prozkoumání výsledných dokumentů se ukázalo, že nejsou příliš relevantní pro dotaz.
    Rostoucí funkce průměrné kosinové vzdálenosti v závislosti na K se láme zhruba okolo bodu K=15, což odpovídá předchozímu experimentu.</p>

    <p>Zároveň se ukázalo, že lemmatizace dotazu nemá žádný vliv na výsledky (křivka průměrné vzdálenosti s lemmatizací kopíruje křivku bez lemmatizace).</p>
</div>
<h2 id="diskuze">Diskuze</h2>
<p>Největším problémem modelu je, že pokud je mu zadán dotaz, který se neobjevuje v žádném z dokumentů a ani v žádném z konceptů, tedy vektor tohoto dotazu je nulový, všechny dokumenty v kolekci jsou stejně dobré, tedy mají stejnou kosinovou vzdálenost. Model proto vrátí jako nejlepší výsledek první dokument v kolekci (shodou náhod o Pittsburg Penguins a Jaromíru Jágrovi).</p>
<p>Dalším nedostatkem je řešení sekvenčního prohledávání. V ideálním případě by mělo být realizováno pomocí nastavení počtu konceptů K na maximální hodnotu (v našem případě počet dokumentů).
Pro takto vysokou hodnotu (téměř 20000) nám však nestačila operační paměť a program zkolaboval.</p>
<h2 id="z-v-r">Závěr</h2>
<p>Podařilo se nám implementovat LSI vektorový model k information retrieval. Při zadání dotazu, který je možné v dokumentech najít, model vrací relevantní výsledky.</p>
<p>Při řešení jsme se potýkali s menšími problémy, nejzávažnější pro logiku modelu bylo správné zobrazování dottazu do prostoru konceptu. Samozřejmě nemohly chybět ani zádrhely s webovým GUI.</p>
<p>Projekt hodnotíme jako zajímavý a přínosný.</p>

{%  endblock %}